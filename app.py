import streamlit as st
import google.generativeai as genai
from PIL import Image
import tempfile
import os
import time

# --- Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ Î£Î•Î›Î™Î”Î‘Î£ ---
st.set_page_config(
    page_title="HVAC Expert Pro",
    page_icon="ğŸ”§",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# --- CSS (ÎšÎ±Î¸Î±ÏÎ® Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ·) ---
st.markdown("""
    <style>
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
        .stDeployButton {display:none;}
        .stChatMessage { border-radius: 12px; }
        /* ÎšÎ¿Ï…Î¼Ï€Î¯ ÎšÎ¬Î¼ÎµÏÎ±Ï‚ */
        div[data-testid="stCameraInput"] button {
            background-color: #ef4444; color: white; border: none;
        }
    </style>
""", unsafe_allow_html=True)

# --- SIDEBAR (Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚) ---
with st.sidebar:
    st.title("âš™ï¸ Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚")
    api_key = st.text_input("ğŸ”‘ API Key", type="password", placeholder="ÎšÏ‰Î´Î¹ÎºÏŒÏ‚ ÎµÎ´Ï...")
    if api_key:
        genai.configure(api_key=api_key)
        st.success("Î£Ï…Î½Î´Î­Î¸Î·ÎºÎµ!")
    
    st.divider()
    model_option = st.selectbox("ÎœÎ¿Î½Ï„Î­Î»Î¿ AI", ["gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"])
    st.caption("v3.0 Media Edition")

# --- MAIN HEADER ---
st.title("ğŸ”§ HVAC Expert")

if not api_key:
    st.warning("â¬…ï¸ **Î Î¬Ï„Î± Ï„Î¿ Î²ÎµÎ»Î¬ÎºÎ¹ Ï€Î¬Î½Ï‰ Î±ÏÎ¹ÏƒÏ„ÎµÏÎ¬ (>)** Î³Î¹Î± Î½Î± Î²Î¬Î»ÎµÎ¹Ï‚ ÎºÏ‰Î´Î¹ÎºÏŒ!")
    st.stop()

# --- Î•Î Î™Î›ÎŸÎ“Î— Î•Î™Î”Î™ÎšÎŸÎ¤Î—Î¤Î‘Î£ ---
col1, col2, col3 = st.columns(3)
if "mode" not in st.session_state: st.session_state.mode = "Î¤ÎµÏ‡Î½Î¹ÎºÏŒÏ‚ HVAC"

with col1:
    if st.button("â„ï¸ AC", use_container_width=True): st.session_state.mode = "Î¤ÎµÏ‡Î½Î¹ÎºÏŒÏ‚ ÎšÎ»Î¹Î¼Î±Ï„Î¹ÏƒÎ¼Î¿Ï"
with col2:
    if st.button("ğŸ§Š Î¨ÏÎ¾Î·", use_container_width=True): st.session_state.mode = "Î¨Ï…ÎºÏ„Î¹ÎºÏŒÏ‚"
with col3:
    if st.button("ğŸ”¥ Î‘Î­ÏÎ¹Î¿", use_container_width=True): st.session_state.mode = "Î¤ÎµÏ‡Î½Î¹ÎºÏŒÏ‚ ÎšÎ±Ï…ÏƒÏ„Î®ÏÏ‰Î½"

st.caption(f"Î•Î¹Î´Î¹ÎºÏŒÏ„Î·Ï„Î±: **{st.session_state.mode}**")

# --- Î Î•Î¡Î™ÎŸÎ§Î— Î ÎŸÎ›Î¥ÎœÎ•Î£Î©Î (CAMERA & UPLOAD) ---
with st.container():
    # Tab 1: Live Photo
    # Tab 2: Upload (Video/Photo/PDF)
    tab1, tab2 = st.tabs(["ğŸ“¸ Live Î¦ÏÏ„Î¿", "ğŸ“‚ Î‘Î½Î­Î²Î±ÏƒÎ¼Î± (Video/Files)"])
    
    with tab1:
        camera_img = st.camera_input("Î¤ÏÎ¬Î²Î± Ï†Ï‰Ï„Î¿Î³ÏÎ±Ï†Î¯Î± Ï„ÏÏÎ±")
    
    with tab2:
        uploaded_files = st.file_uploader(
            "Î•Ï€Î­Î»ÎµÎ¾Îµ Î±Ï€ÏŒ Ï„Î¿ ÎºÎ¹Î½Î·Ï„ÏŒ (Î’Î¯Î½Ï„ÎµÎ¿, Î•Î¹ÎºÏŒÎ½ÎµÏ‚, PDF)", 
            accept_multiple_files=True, 
            type=['jpg', 'png', 'jpeg', 'pdf', 'mp4', 'mov', 'avi']
        )

# --- Î™Î£Î¤ÎŸÎ¡Î™ÎšÎŸ CHAT ---
if "messages" not in st.session_state: st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Î›Î•Î™Î¤ÎŸÎ¥Î¡Î“Î™Î‘ Î•Î Î•ÎÎ•Î¡Î“Î‘Î£Î™Î‘Î£ Î‘Î¡Î§Î•Î™Î©Î (Heavy Lifting) ---
def process_file_for_gemini(uploaded_file):
    """Î•Ï„Î¿Î¹Î¼Î¬Î¶ÎµÎ¹ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ (Î’Î¯Î½Ï„ÎµÎ¿/PDF/Î•Î¹ÎºÏŒÎ½Î±) Î³Î¹Î± Ï„Î¿ Gemini"""
    try:
        # 1. Î£ÏÏƒÎ¹Î¼Î¿ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¿Ï Î±ÏÏ‡ÎµÎ¯Î¿Ï… ÏƒÏ„Î¿Î½ Î´Î¯ÏƒÎºÎ¿ (Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î¿ Î³Î¹Î± Î²Î¯Î½Ï„ÎµÎ¿)
        suffix = f".{uploaded_file.name.split('.')[-1]}"
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_path = tmp.name

        # 2. Î‘Î Î•Î™ÎÎ‘Î™ Î’Î™ÎÎ¤Î•ÎŸ Î‰ PDF (Î˜Î­Î»ÎµÎ¹ Upload API)
        mime_type = uploaded_file.type
        if "video" in mime_type or "pdf" in mime_type:
            with st.spinner(f"ğŸ“¤ Î‘Î½ÎµÎ²Î¬Î¶Ï‰ {uploaded_file.name}..."):
                myfile = genai.upload_file(tmp_path, mime_type=mime_type)
            
            # Î‘Î½ ÎµÎ¯Î½Î±Î¹ Î²Î¯Î½Ï„ÎµÎ¿, Ï€ÎµÏÎ¹Î¼Î­Î½Î¿Ï…Î¼Îµ Î½Î± Î³Î¯Î½ÎµÎ¹ process
            if "video" in mime_type:
                with st.spinner("â³ Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î²Î¯Î½Ï„ÎµÎ¿ Î±Ï€ÏŒ Google..."):
                    while myfile.state.name == "PROCESSING":
                        time.sleep(2)
                        myfile = genai.get_file(myfile.name)
                    if myfile.state.name == "FAILED":
                        raise ValueError("Î— ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î±Ï€Î­Ï„Ï…Ï‡Îµ.")
            return myfile

        # 3. Î‘Î Î•Î™ÎÎ‘Î™ Î•Î™ÎšÎŸÎÎ‘ (Î‘Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ Î¬Î½Î¿Î¹Î³Î¼Î±)
        elif "image" in mime_type:
            return Image.open(tmp_path)

    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï…: {e}")
        return None
    finally:
        # Î£Î²Î®ÏƒÎ¹Î¼Î¿ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¿Ï Î±ÏÏ‡ÎµÎ¯Î¿Ï… Î³Î¹Î± Î½Î± Î¼Î·Î½ Î³ÎµÎ¼Î¯Î¶ÎµÎ¹ Î¿ Î´Î¯ÏƒÎºÎ¿Ï‚
        if 'tmp_path' in locals() and os.path.exists(tmp_path):
            os.remove(tmp_path)

# --- INPUT & RESPONSE ---
prompt = st.chat_input("Î ÎµÏÎ¹Î­Î³ÏÎ±ÏˆÎµ Ï„Î¿ Ï€ÏÏŒÎ²Î»Î·Î¼Î±...")

if prompt:
    # 1. Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÎµÏÏÏ„Î·ÏƒÎ·Ï‚
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. Î£Ï…Î»Î»Î¿Î³Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Media)
    media_items = []
    
    # Î‘Ï€ÏŒ ÎšÎ¬Î¼ÎµÏÎ±
    if camera_img:
        media_items.append(Image.open(camera_img))
        st.toast("ğŸ“ Î ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎµ Live Î¦Ï‰Ï„Î¿Î³ÏÎ±Ï†Î¯Î±")

    # Î‘Ï€ÏŒ Uploads (Î’Î¯Î½Ï„ÎµÎ¿/PDF/Gallery)
    if uploaded_files:
        for f in uploaded_files:
            processed = process_file_for_gemini(f)
            if processed:
                media_items.append(processed)
                st.toast(f"ğŸ“ Î ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎµ: {f.name}")

    # 3. ÎšÎ»Î®ÏƒÎ· ÏƒÏ„Î¿ AI
    with st.chat_message("assistant"):
        with st.spinner("ğŸ§  ÎŸ Î¤ÎµÏ‡Î½Î¹ÎºÏŒÏ‚ ÏƒÎºÎ­Ï†Ï„ÎµÏ„Î±Î¹..."):
            try:
                model = genai.GenerativeModel(st.session_state.get('model_option', 'gemini-2.0-flash'))
                
                # Î¦Ï„Î¹Î¬Ï‡Î½Î¿Ï…Î¼Îµ Ï„Î¿ Î¼Î®Î½Ï…Î¼Î±
                msg_content = [f"Î•Î¯ÏƒÎ±Î¹ {st.session_state.mode}. Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Ï„ÎµÏ‡Î½Î¹ÎºÎ¬ ÏƒÏ„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬.\nÎ•ÏÏÏ„Î·ÏƒÎ·: {prompt}"]
                msg_content.extend(media_items) # Î ÏÎ¿ÏƒÎ¸Î­Ï„Î¿Ï…Î¼Îµ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î±
                
                response = model.generate_content(msg_content)
                st.markdown(response.text)
                
                # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            
            except Exception as e:
                st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î±: {str(e)}")
