import streamlit as st
import google.generativeai as genai
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from PIL import Image
import io
import json
import tempfile
import os
import time

# --- Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ ---
st.set_page_config(page_title="HVAC Auto-Pilot", page_icon="ğŸ¤–", layout="centered")

# CSS
st.markdown("""<style>
    #MainMenu {visibility: hidden;} footer {visibility: hidden;} .stDeployButton {display:none;}
    div[data-testid="stCameraInput"] button {background-color: #ef4444; color: white;}
    .stChatMessage { border-radius: 12px; }
</style>""", unsafe_allow_html=True)

# --- Î£Î¥ÎÎ”Î•Î£Î— (AUTO-REPAIR KEY) ---
drive_service = None
auth_status = "â³ Î•ÎºÎºÎ¯Î½Î·ÏƒÎ·..."

try:
    if "GEMINI_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GEMINI_KEY"])
    
    if "GCP_SERVICE_ACCOUNT" in st.secrets:
        gcp_info = json.loads(st.secrets["GCP_SERVICE_ACCOUNT"])
        if "private_key" in gcp_info:
            gcp_info["private_key"] = gcp_info["private_key"].replace("\\n", "\n")
        
        creds = service_account.Credentials.from_service_account_info(
            gcp_info, scopes=['https://www.googleapis.com/auth/drive.readonly']
        )
        drive_service = build('drive', 'v3', credentials=creds)
        auth_status = "âœ… Î£ÏÏƒÏ„Î·Î¼Î±: ON"
    else:
        auth_status = "âš ï¸ Î›ÎµÎ¯Ï€Î¿Ï…Î½ Secrets"
except Exception as e:
    auth_status = f"âŒ Î£Ï†Î¬Î»Î¼Î±: {e}"

# --- STATE MANAGEMENT (ÎœÎÎ—ÎœÎ—) ---
if "messages" not in st.session_state: st.session_state.messages = []
if "active_file" not in st.session_state: st.session_state.active_file = None # Î¤Î¿ manual Ï€Î¿Ï… Î´Î¹Î±Î²Î¬Î¶ÎµÎ¹ Ï„ÏÏÎ±
if "file_list" not in st.session_state: st.session_state.file_list = [] # Î›Î¯ÏƒÏ„Î± Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Drive

# --- FUNCTIONS ---
def get_drive_files():
    """Î¦Î­ÏÎ½ÎµÎ¹ Ï„Î· Î»Î¯ÏƒÏ„Î± Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Î±Ï€ÏŒ Ï„Î¿ Drive (Cache)"""
    if not drive_service: return []
    try:
        # Î‘Î½ Î­Ï‡Î¿Ï…Î¼Îµ Î®Î´Î· Ï„Î· Î»Î¯ÏƒÏ„Î±, Î´ÎµÎ½ Î¾Î±Î½Î±ÏÏ‰Ï„Î¬Î¼Îµ Ï„Î·Î½ Google (Î³Î¹Î± Ï„Î±Ï‡ÏÏ„Î·Ï„Î±)
        if st.session_state.file_list: return st.session_state.file_list
        
        q = "mimeType != 'application/vnd.google-apps.folder' and trashed = false"
        res = drive_service.files().list(q=q, fields="files(id, name, mimeType)", pageSize=50).execute()
        files = res.get('files', [])
        st.session_state.file_list = files
        return files
    except: return []

def find_relevant_file(query, files):
    """Î¨Î¬Ï‡Î½ÎµÎ¹ Ï€Î¿Î¹Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Ï„Î±Î¹ÏÎ¹Î¬Î¶ÎµÎ¹ Î¼Îµ Î±Ï…Ï„ÏŒ Ï€Î¿Ï… Î­Î³ÏÎ±ÏˆÎµ Î¿ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚"""
    query = query.lower()
    best_match = None
    for f in files:
        # Î‘Ï€Î»Î® Î»Î¿Î³Î¹ÎºÎ®: Î‘Î½ Ï„Î¿ ÏŒÎ½Î¿Î¼Î± Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï… Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÏ„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ·
        # Ï€.Ï‡. Î•ÏÏÏ„Î·ÏƒÎ· "Daikin" -> Î‘ÏÏ‡ÎµÎ¯Î¿ "Manual_Daikin.pdf"
        fname = f['name'].lower().replace(".pdf", "").replace(".jpg", "")
        if fname in query or query in fname:
            # Î•Î¾Î±Î¹ÏÎ¿ÏÎ¼Îµ Ï€Î¿Î»Ï Î¼Î¹ÎºÏÎ­Ï‚ Î»Î­Î¾ÎµÎ¹Ï‚ Î³Î¹Î± Î½Î± Î¼Î·Î½ Î¼Ï€ÎµÏÎ´ÎµÏÎµÏ„Î±Î¹
            if len(fname) > 3: 
                best_match = f
                break
    return best_match

def load_file_to_gemini(file_id, file_name):
    """ÎšÎ±Ï„ÎµÎ²Î¬Î¶ÎµÎ¹ ÎºÎ±Î¹ Î±Î½ÎµÎ²Î¬Î¶ÎµÎ¹ ÏƒÏ„Î¿ Gemini"""
    with st.spinner(f"ğŸ“– ÎœÎµÎ»ÎµÏ„Î¬Ï‰ Ï„Î¿ ÎµÎ³Ï‡ÎµÎ¹ÏÎ¯Î´Î¹Î¿: {file_name}..."):
        # 1. Download form Drive
        req = drive_service.files().get_media(fileId=file_id)
        fh = io.BytesIO()
        downloader = MediaIoBaseDownload(fh, req)
        done = False
        while done is False: status, done = downloader.next_chunk()
        fh.seek(0)
        
        # 2. Save Temp
        suffix = ".pdf" if "pdf" in file_name.lower() else ".jpg"
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(fh.getvalue())
            tmp_path = tmp.name
        
        # 3. Upload to Gemini
        g_file = genai.upload_file(tmp_path)
        
        # Wait if video (optional check)
        if "video" in file_name:
             while g_file.state.name == "PROCESSING": time.sleep(1); g_file = genai.get_file(g_file.name)
             
        return g_file

def clear_chat():
    """ÎšÎ±Î¸Î±ÏÎ¯Î¶ÎµÎ¹ Ï„Î± Ï€Î¬Î½Ï„Î± Î³Î¹Î± Î½Î­Î± Î²Î»Î¬Î²Î·"""
    st.session_state.messages = []
    st.session_state.active_file = None
    st.toast("ÎœÎ½Î®Î¼Î· ÎºÎ±Î¸Î±ÏÎ¯ÏƒÏ„Î·ÎºÎµ! ÎˆÏ„Î¿Î¹Î¼Î¿Ï‚ Î³Î¹Î± Î½Î­Î± Î²Î»Î¬Î²Î·.", icon="ğŸ§¹")

# --- SIDEBAR ---
with st.sidebar:
    st.title("ğŸ›ï¸ Î§ÎµÎ¹ÏÎ¹ÏƒÏ„Î®ÏÎ¹Î¿")
    st.caption(auth_status)
    
    if st.button("ğŸ—‘ï¸ ÎÎ•Î‘ Î’Î›Î‘Î’Î— / RESET", type="primary", use_container_width=True):
        clear_chat()
    
    st.divider()
    
    # Î§ÎµÎ¹ÏÎ¿ÎºÎ¯Î½Î·Ï„Î· ÎµÏ€Î¹Î»Î¿Î³Î® (Î±Î½ Ï„Î¿ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î¿ Î´ÎµÎ½ Ï€Î¹Î¬ÏƒÎµÎ¹)
    st.subheader("ğŸ“‚ Î•Î½ÎµÏÎ³ÏŒ Î‘ÏÏ‡ÎµÎ¯Î¿")
    if st.session_state.active_file:
        st.info(f"ğŸ“„ {st.session_state.active_file['user_name']}")
    else:
        st.warning("ÎšÎ±Î½Î­Î½Î± (Î“ÎµÎ½Î¹ÎºÎ® Î“Î½ÏÏƒÎ·)")
        
    st.divider()
    if st.button("ğŸ”„ Î‘Î½Î±Î½Î­Ï‰ÏƒÎ· Î›Î¯ÏƒÏ„Î±Ï‚ Drive"):
        st.session_state.file_list = []
        get_drive_files()
        st.success("Î›Î¯ÏƒÏ„Î± ÎµÎ½Î·Î¼ÎµÏÏÎ¸Î·ÎºÎµ")

# --- MAIN UI ---
st.title("ğŸ¤– HVAC Auto-Pilot")

# Î•Î¹Î´Î¹ÎºÏŒÏ„Î·Ï„Î±
col1, col2, col3 = st.columns(3)
if "mode" not in st.session_state: st.session_state.mode = "Î¤ÎµÏ‡Î½Î¹ÎºÏŒÏ‚ HVAC"
if col1.button("â„ï¸ AC", use_container_width=True): st.session_state.mode = "Î¤ÎµÏ‡Î½Î¹ÎºÏŒÏ‚ ÎšÎ»Î¹Î¼Î±Ï„Î¹ÏƒÎ¼Î¿Ï"
if col2.button("ğŸ§Š Î¨ÏÎ¾Î·", use_container_width=True): st.session_state.mode = "Î¨Ï…ÎºÏ„Î¹ÎºÏŒÏ‚"
if col3.button("ğŸ”¥ Î‘Î­ÏÎ¹Î¿", use_container_width=True): st.session_state.mode = "Î¤ÎµÏ‡Î½Î¹ÎºÏŒÏ‚ ÎšÎ±Ï…ÏƒÏ„Î®ÏÏ‰Î½"
st.caption(f"Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±: **{st.session_state.mode}**")

# Chat History
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

# --- INPUT LOGIC ---
prompt = st.chat_input("Î“ÏÎ¬ÏˆÎµ Î²Î»Î¬Î²Î· Î® Î¼Î¬ÏÎºÎ± (Ï€.Ï‡. 'Error E1 ÏƒÎµ Daikin')...")

if prompt:
    # 1. Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÎµÏÏÏ„Î·ÏƒÎ·Ï‚
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    # 2. Î›ÎŸÎ“Î™ÎšÎ— Î‘Î¥Î¤ÎŸÎœÎ‘Î¤ÎŸÎ¥ Î Î™Î›ÎŸÎ¤ÎŸÎ¥
    # Î‘Î½ Î”Î•Î Î­Ï‡Î¿Ï…Î¼Îµ Î®Î´Î· Î±Î½Î¿Î¹Ï‡Ï„ÏŒ manual, ÏˆÎ¬Ï‡Î½Î¿Ï…Î¼Îµ Ï„ÏÏÎ±
    if not st.session_state.active_file:
        files = get_drive_files() # Î¦Î­ÏÎ½Î¿Ï…Î¼Îµ Î»Î¯ÏƒÏ„Î±
        match = find_relevant_file(prompt, files) # Î¨Î¬Ï‡Î½Î¿Ï…Î¼Îµ match
        
        if match:
            # Î’Î¡Î—ÎšÎ‘ÎœÎ• Î‘Î¡Î§Î•Î™ÎŸ!
            msg_placeholder = st.empty()
            msg_placeholder.info(f"ğŸ” Î’ÏÎ®ÎºÎ± ÏƒÏ‡ÎµÏ„Î¹ÎºÏŒ Î±ÏÏ‡ÎµÎ¯Î¿: **{match['name']}**. Î¤Î¿ Î±Î½Î¿Î¯Î³Ï‰...")
            
            # Î‘Î½Î­Î²Î±ÏƒÎ¼Î± ÏƒÏ„Î¿ AI
            gemini_file = load_file_to_gemini(match['id'], match['name'])
            
            # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î· Î¼Î½Î®Î¼Î·
            st.session_state.active_file = {
                "obj": gemini_file,
                "user_name": match['name']
            }
            msg_placeholder.empty() # Î£Î²Î®Î½Î¿Ï…Î¼Îµ Ï„Î¿ Î¼Î®Î½Ï…Î¼Î± "ÏˆÎ¬Ï‡Î½Ï‰"
        else:
            # Î”ÎµÎ½ Î²ÏÎ®ÎºÎ±Î¼Îµ, Ï€Î¬Î¼Îµ Î¼Îµ Î³ÎµÎ½Î¹ÎºÎ® Î³Î½ÏÏƒÎ·
            pass

    # 3. Î•Î¤ÎŸÎ™ÎœÎ‘Î£Î™Î‘ Î‘Î Î‘ÎÎ¤Î—Î£Î—Î£
    model = genai.GenerativeModel("gemini-2.0-flash")
    
    parts = [f"Î•Î¯ÏƒÎ±Î¹ {st.session_state.mode}. Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ ÏƒÏ„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬."]
    
    # Î‘Î½ Î­Ï‡Î¿Ï…Î¼Îµ ÎµÎ½ÎµÏÎ³ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿, Ï„Î¿ Î²Î¬Î¶Î¿Ï…Î¼Îµ ÏƒÏ„Î· ÏƒÏ…Î¶Î®Ï„Î·ÏƒÎ·
    if st.session_state.active_file:
        parts.append(st.session_state.active_file["obj"])
        parts.append(f"Î’Î¬ÏƒÎ· Ï„Î¿Ï… ÎµÎ³Ï‡ÎµÎ¹ÏÎ¹Î´Î¯Î¿Ï… '{st.session_state.active_file['user_name']}', Î±Ï€Î¬Î½Ï„Î·ÏƒÎµ:")
    else:
        parts.append("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÎµÎ³Ï‡ÎµÎ¹ÏÎ¯Î´Î¹Î¿. Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î²Î¬ÏƒÎµÎ¹ Ï„Î·Ï‚ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±Ï‚ ÏƒÎ¿Ï…:")
        
    parts.append(prompt)

    # 4. STREAMING RESPONSE
    with st.chat_message("assistant"):
        try:
            stream = model.generate_content(parts, stream=True)
            response = st.write_stream(stream)
            st.session_state.messages.append({"role": "assistant", "content": response})
        except Exception as e:
            st.error(f"Î£Ï†Î¬Î»Î¼Î±: {e}")
